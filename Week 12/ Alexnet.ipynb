{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Alexnet.ipynb","provenance":[{"file_id":"https://github.com/Rifqi1320/Rifqi-ML/blob/main/Week12/Alexnet.ipynb","timestamp":1656157479529}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Deep Convolutional Neural Networks (AlexNet)**"],"metadata":{"id":"DWteNdHfLEln"}},{"cell_type":"markdown","source":["AlexNet, which employed an 8-layer CNN, won the ImageNet Large Scale Visual Recognition Challenge 2012 by a phenomenally large margin. This network showed, for the first time, that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision."],"metadata":{"id":"z1tpcPiYLHMm"}},{"cell_type":"code","source":["# Install d2l Module\n","!pip install d2l\n","\n","# Import libraries\n","import tensorflow as tf\n","from d2l import tensorflow as d2l\n","\n","\n","def net():\n","    return tf.keras.models.Sequential([\n","        # Here, we use a larger 11 x 11 window to capture objects. At the same\n","        # time, we use a stride of 4 to greatly reduce the height and width of\n","        # the output. Here, the number of output channels is much larger than\n","        # that in LeNet\n","        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,\n","                               activation='relu'),\n","        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n","        # Make the convolution window smaller, set padding to 2 for consistent\n","        # height and width across the input and output, and increase the\n","        # number of output channels\n","        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n","                               activation='relu'),\n","        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n","        # Use three successive convolutional layers and a smaller convolution\n","        # window. Except for the final convolutional layer, the number of\n","        # output channels is further increased. Pooling layers are not used to\n","        # reduce the height and width of input after the first two\n","        # convolutional layers\n","        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n","                               activation='relu'),\n","        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n","                               activation='relu'),\n","        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n","                               activation='relu'),\n","        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n","        tf.keras.layers.Flatten(),\n","        # Here, the number of outputs of the fully-connected layer is several\n","        # times larger than that in LeNet. Use the dropout layer to mitigate\n","        # overfitting\n","        tf.keras.layers.Dense(4096, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(4096, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        # Output layer. Since we are using Fashion-MNIST, the number of\n","        # classes is 10, instead of 1000 as in the paper\n","        tf.keras.layers.Dense(10)\n","    ])"],"metadata":{"id":"gDZU2A_-LIyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Construct a single-channel data example\n","X = tf.random.uniform((1, 224, 224, 1))\n","for layer in net().layers:\n","    X = layer(X)\n","    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"],"metadata":{"id":"gYadkZ74LddJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reading dataset\n","batch_size = 128\n","train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"],"metadata":{"id":"tJkWeDb2LgOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training\n","lr, num_epochs = 0.01, 10\n","d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"],"metadata":{"id":"P1tLiStEMjMu"},"execution_count":null,"outputs":[]}]}